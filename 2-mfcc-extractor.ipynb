{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MFCC Extractor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "dataset_path = \"data/archive/Data/genres_original\"\n",
    "json_path = \"data/gtzan_mfcc_json.json\"\n",
    "sr = 22050\n",
    "duration = 30   # seconds\n",
    "total_samples = sr * duration\n",
    "num_mfcc = 13\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "segments_per_track = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create a dictionary to store labels of all the songs' MFCCs.\n",
    "* `mapping` consists of all the 10 genres.\n",
    "* `labels` consists of the label for each of the 1000 songs.\n",
    " 0 corresponds to blues, 1 for classical, 2 for country and so on.\n",
    " Since each songs has a label, there will be 100 zeroes, 100 ones, 100 twos, and so on.\n",
    "* `mfcc` consists of individual mfcc values (grouped by 13 to be called an MFCC) for every song.\n",
    "Every song consists of `22050 * 30 = 661500` total number of samples,\n",
    "which are divided into 10 segments. So each segment has 66150 samples.\n",
    "The number of MFCCs in each segment would be determined by `hop_length` (`=512`),\n",
    "which would be `ceil(66150 / 512) = 130` MFCCs in each segment."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "No. of segments:  10\n",
      "No. of samples per segment:  66150\n",
      "No. of MFCCs per segment:  130\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# dictionary to store mapping, labels, and MFCCs\n",
    "data = {\n",
    "    \"mapping\": [],\n",
    "    \"labels\": [],\n",
    "    \"mfcc\": []\n",
    "}\n",
    "print(\"No. of segments: \", segments_per_track)\n",
    "\n",
    "samples_per_segment = int(total_samples / segments_per_track)\n",
    "print(\"No. of samples per segment: \", samples_per_segment)\n",
    "\n",
    "num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "print(\"No. of MFCCs per segment: \", num_mfcc_vectors_per_segment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%    \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Processing: blues\n",
      "Processing: classical\n",
      "Processing: country\n",
      "Processing: disco\n",
      "Processing: hiphop\n",
      "Processing: jazz\n",
      "Processing: metal\n",
      "Processing: pop\n",
      "Processing: reggae\n",
      "Processing: rock\n",
      "\n",
      "MFCCs extracted. Saving to JSON file...\n",
      "Done\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# loop through all genre sub-folder\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "    # ensure we're processing a genre sub-folder level\n",
    "    if dirpath is not dataset_path:\n",
    "\n",
    "        # save genre label (i.e., sub-folder name) in the mapping\n",
    "        # For Windows, '\\\\' is used. For Linux, change to '/'\n",
    "        semantic_label = dirpath.split('\\\\')[-1]\n",
    "        # print(dirpath)\n",
    "        # print(semantic_label)\n",
    "        data[\"mapping\"].append(semantic_label)\n",
    "        print(\"Processing:\", semantic_label)\n",
    "\n",
    "        # process all audio files in genre sub-dir\n",
    "        for f in filenames:\n",
    "\n",
    "            # load audio file\n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            signal, sample_rate = librosa.load(file_path, sr=sr)\n",
    "\n",
    "            # process all segments of audio file\n",
    "            for d in range(segments_per_track):\n",
    "\n",
    "                # calculate start and finish sample for current segment\n",
    "                start = samples_per_segment * d\n",
    "                finish = start + samples_per_segment\n",
    "\n",
    "                # extract mfcc\n",
    "                mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
    "                                            hop_length=hop_length)\n",
    "                mfcc = mfcc.T\n",
    "                # store only mfcc feature with expected number of vectors\n",
    "                if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                    data[\"mfcc\"].append(mfcc.tolist())\n",
    "                    data[\"labels\"].append(i - 1)\n",
    "\n",
    "print(\"\\nMFCCs extracted. Saving to JSON file...\")\n",
    "# save MFCCs to json file\n",
    "with open(json_path, \"w\") as fp:\n",
    "    json.dump(data, fp, indent=4)\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* There are total 1000-1 = 999 songs (one song removed as the file was corrupted)\n",
    "So there should ideally be 9990 total number of segments, which would serve\n",
    "as the input to the training part.\n",
    "The dimensions would be (9990, 130, 13)\n",
    "* The above dimensions are under the assumption that every song is __exactly__ 30 seconds in duration."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Labels: 9986\n",
      "MFCCs: 9986\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Labels:\", len(data[\"labels\"]))\n",
    "print(\"MFCCs:\", len(data[\"mfcc\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We see that there are slightly less number of segments as expected.\n",
    "There are 4 segments less. The possible reason could be that not\n",
    "every song is exactly 30 seconds, there could be +/- few milliseconds \n",
    "for each song. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}